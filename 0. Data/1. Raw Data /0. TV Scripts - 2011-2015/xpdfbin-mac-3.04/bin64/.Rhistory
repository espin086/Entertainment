coeftest(random)
coeftest(random, vcovHC) # Heteroskedasticity consistent coefficients
coeftest(random, vcovHC(random, type = "HC3")) # Heteroskedasticity consistent coefficients, type 3
t(sapply(c("HC0", "HC1", "HC2", "HC3", "HC4"), function(x) sqrt(diag(vcovHC(random, type = x)))))
#Heteroskedasticity for Random Effects
coeftest(fixed)
coeftest(fixed, vcovHC) # Heteroskedasticity consistent coefficients
coeftest(fixed, vcovHC(fixed, method = "arellano")) # Heteroskedasticity consistent coefficients (Arellano)
coeftest(fixed, vcovHC(fixed, type = "HC3")) # Heteroskedasticity consistent coefficients, type 3
t(sapply(c("HC0", "HC1", "HC2", "HC3", "HC4"), function(x) sqrt(diag(vcovHC(fixed, type = x)))))
#Based the Princeton University Panel Regression Diagnostics document
#http://www.princeton.edu/~otorres/Panel101R.pdf
#################################
#Panel Regression Diagnostic
library(plm)
data("Grunfeld", package = "AER")
#Exploring panel data
coplot(invest ~ year | firm,  type="l", data = Grunfeld)
library(car)
scatterplot(invest ~ year | firm,
smooth = TRUE,
reg.line = FALSE,
data = Grunfeld)
library(gplots)
plotmeans(invest ~ firm,
main="Heterogeineity across firms",
data=Grunfeld)
plotmeans(invest ~ year,
main="Heterogeineity across years",
data=Grunfeld)
###################################
#OLS Regression Model
ols <-lm(log(invest) ~ log(value) + log(capital),
data=Grunfeld)
summary(ols)
###################################
#Fixed Effects Model
fixed <- plm(log(invest) ~ log(value) + log(capital),
data=Grunfeld,
index=c("firm", "year"),
model="within")
summary(fixed)
#displaying fixed effects for each country
fixef(fixed)
#if p-value less than 0.05 then fixed effects is a better choice
pFtest(fixed, ols)
###################################
#Random Effects Model
random <- plm(log(invest) ~ log(value) + log(capital),
data=Grunfeld,
index=c("firm", "year"),
model="random")
summary(random)
###################################
#deciding between fixed and random effects
#if p-value is less than 0.05 then used fixed effects
phtest(fixed, random)
###################################
#Other diagnostic tests
#Testing for time fixed effects, if p-value is less than 0.05 than use fixed effects
fixed.time <- plm(log(invest) ~ log(value) + log(capital) + factor(year),
data=Grunfeld,
index=c("firm","year"), model="within")
summary(fixed.time)
pFtest(fixed.time, fixed)
#Random Effects or OLS
#if p-value is less than 0.05 then use Random Effects
pool <- plm(log(invest) ~ log(value) + log(capital),
data=Grunfeld, index=c("firm", "year"),
model="pooling")
summary(pool)
plmtest(pool, type=c("bp"))
#Testing for cross section dependence
#if p is less than 0.05 then we have cross sectional independence
pcdtest(fixed, test = c("lm"))
#Testing for serial correlation
#if p is less than 0.05 than there is serial correlation
pbgtest(fixed)
#Testing for unit root/stationary
#If p-value < 0.05 then no unit roots present.
Panel.set <- plm.data(Grunfeld, index = c("firm", "year"))
library(tseries)
adf.test(Panel.set$invest, k=2)
#Testing for heteroskedasticity
#If p-value < 0.05 heteroskedasticity is present
library(lmtest)
bptest(log(invest) ~ log(value) + log(capital) + factor(firm),
data = Grunfeld, studentize=F)
#The --vcovHC– function estimates three heteroskedasticity-consistent covariance estimators:
#"white1" - for general heteroskedasticity but no serial correlation. Recommended for random effects.
#"white2" - is "white1" restricted to a common variance within groups. Recommended for random effects.
#"arellano" - both heteroskedasticity and serial correlation. Recommended for fixed effects.
#The following options apply*:
#HC0 - heteroskedasticity consistent. The default.
#HC1,HC2, HC3 – Recommended for small samples. HC3 gives less weight to influential observations.
#HC4 - small samples with influential observations
#HAC - heteroskedasticity and autocorrelation consistent (type ?vcovHAC for more details)
#Heteroskedasticity for Random Effects
coeftest(random)
coeftest(random, vcovHC) # Heteroskedasticity consistent coefficients
coeftest(random, vcovHC(random, type = "HC3")) # Heteroskedasticity consistent coefficients, type 3
t(sapply(c("HC0", "HC1", "HC2", "HC3", "HC4"), function(x) sqrt(diag(vcovHC(random, type = x)))))
#Heteroskedasticity for Random Effects
coeftest(fixed)
coeftest(fixed, vcovHC) # Heteroskedasticity consistent coefficients
coeftest(fixed, vcovHC(fixed, method = "arellano")) # Heteroskedasticity consistent coefficients (Arellano)
coeftest(fixed, vcovHC(fixed, type = "HC3")) # Heteroskedasticity consistent coefficients, type 3
t(sapply(c("HC0", "HC1", "HC2", "HC3", "HC4"), function(x) sqrt(diag(vcovHC(fixed, type = x)))))
summary(fixed)
fixed[1]
fixed[2]
fixed[3]
fixed[4]
fixed[5]
fixed[6]
fixed[7]
fixed[8]
fixed[9]
summary(fixed)
total.cash <- 885
total.cash <- 885
cable.bill <- 67.99
electric.bill <- 99.70
total.cash <- 885
cable.bill <- 67.99
electric.bill <- 99.70
total.expenses <- cable.bill + electric.bill
operating.income <- total.cash - total.expenses
total.cash <- 885
cable.bill <- 67.99
electric.bill <- 99.70
total.expenses <- cable.bill + electric.bill
operating.income <- total.cash - total.expenses
operating.income
total.cash <- 885
cable.bill <- 67.99
electric.bill <- 99.70
student.loans <- 250
total.expenses <- cable.bill + electric.bill + student.loans
operating.income <- total.cash - total.expenses
operating.income
total.cash <- 885
cable.bill <- 67.99
electric.bill <- 99.70
student.loans <- 250
total.expenses <- cable.bill + electric.bill + student.loans
operating.income <- total.cash - total.expenses
operating.income
bassinet.&.diaper.pail <- 310
bassinet.diaper.pail <- 310
total.cash <- 885
cable.bill <- 67.99
electric.bill <- 99.70
student.loans <- 250
bassinet.diaper.pail <- 310
total.expenses <- cable.bill + electric.bill + student.loans + bassinet.diaper.pail
operating.income <- total.cash - total.expenses
operating.income
135000/52
(135000/52)/40
((135000/52)/40)*1.5
install.packages("Zillow", repos="http://www.omegahat.org/R", type="source", dependencies="Depends"))
install.packages("Zillow", repos="http://www.omegahat.org/R", type="source", dependencies="Depends")
install.packages("Zillow",
repos="http://www.omegahat.org/R",
type="source", dependencies="Depends")
library(Zillow)
18000/12
((100000)/6)/12
((100000)/5)/12
((150000)/10)/12
((30000)/3)/12
((100000)/6)/12
1500 + 1400 + 1700 + 1250
850 +
850
850 +1450
850 +1450 + 300
850 +1450 + 300 + 600
6000/12
850*12
17000/12
(32000/3)/12
(42000/6)/12
(8000/2)/12
600 + 900 + 350
(100000/10)/12
(150000/20)/12
1500 + 850 + 850 + 625
(361000/15)/12
(68000/10)/12
(361000/20)/12
1500 + 850 + 850 + 625
(25000/3)/12
4500/12
1400 + 375
install.packages("shiny")
shiny::runApp('Documents/my-shiny-tools/1. Prediction App')
shiny::runApp('Documents/my-shiny-tools/1. Prediction App')
shiny::runApp('Documents/my-shiny-tools/1. Prediction App')
shiny::runApp('Documents/my-shiny-tools/1. Prediction App')
85 + 18 + 2
shiny::runApp('Documents/my-shiny-tools/1. Prediction App')
box_office_mojo_top <- function(num.pages) {
# load required packages
require(XML)
# local helper functions
get_table <- function(u) {
table <- readHTMLTable(u)[[3]]
names(table) <- c("Rank", "Title", "Studio", "Worldwide.Gross", "Domestic.Gross", "Domestic.pct", "Overseas.Gross", "Overseas.pct", "Year")
df <- as.data.frame(lapply(table[-1, ], as.character), stringsAsFactors=FALSE)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
clean_df <- function(df) {
clean <- function(col) {
col <- gsub("$", "", col, fixed = TRUE)
col <- gsub("%", "", col, fixed = TRUE)
col <- gsub(",", "", col, fixed = TRUE)
col <- gsub("^", "", col, fixed = TRUE)
return(col)
}
df <- sapply(df, clean)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
# Main
# Step 1: construct URLs
urls <- paste("http://boxofficemojo.com/alltime/world/?pagenum=", 1:num.pages, "&p=.htm", sep = "")
# Step 2: scrape website
df <- do.call("rbind", lapply(urls, get_table))
# Step 3: clean dataframe
df <- clean_df(df)
# Step 4: set column types
s <- c(1, 4:9)
df[, s] <- sapply(df[, s], as.numeric)
df$Studio <- as.factor(df$Studio)
# step 5: return dataframe
return(df)
}
num.pages <- 5
df <- box_office_mojo_top(num.pages)
View(df)
library(XML)
list.url[["1"]] <- "http://www.boxofficemojo.com/people/"
list.url <- list()
list.url[["1"]] <- "http://www.boxofficemojo.com/people/"
list.url[[1]]
list.url <- list()
list.url[["1"]] <- "http://www.boxofficemojo.com/people/"
table <- readHTMLTable(u)
list.url[[1]]
table <- readHTMLTable(list.url[[1]])
str(table)
table[[1]]
table[[1]]
table[[2]]
table[[3]]
table <- readHTMLTable(list.url[[1]])[[3]]
View(table)
table[-1,]
table <- table[-1,]
View(table)
View(table)
names(table) <- c("Actor", "Total.Gross", "Num.Movies", "Avg.Per.Movie", "No.1 Movie", "Gross.of.No.1.Movie")
View(table)
View(table)
urls <- paste("http://www.boxofficemojo.com/people/?view=Actor&pagenum=", 1:3, "&sort=person&order=ASC&p=.htm", sep = "")
library(XML)
urls <- paste("http://www.boxofficemojo.com/people/?view=Actor&pagenum=", 1:3, "&sort=person&order=ASC&p=.htm", sep = "")
# local helper functions
get_table <- function(u) {
table <- readHTMLTable(u)[[3]]
names(table) <- c("Actor", "Total.Gross", "Num.Movies", "Avg.Per.Movie", "No.1 Movie", "Gross.of.No.1.Movie")
df <- as.data.frame(lapply(table[-1, ], as.character), stringsAsFactors=FALSE)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
library(XML)
# Step 1: construct URLs
urls <- paste("http://www.boxofficemojo.com/people/?view=Actor&pagenum=", 1:3, "&sort=person&order=ASC&p=.htm", sep = "")
# Step 2: scrape website
get_table <- function(u) {
table <- readHTMLTable(u)[[3]]
names(table) <- c("Actor", "Total.Gross", "Num.Movies", "Avg.Per.Movie", "No.1 Movie", "Gross.of.No.1.Movie")
df <- as.data.frame(lapply(table[-1, ], as.character), stringsAsFactors=FALSE)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
df <- do.call("rbind", lapply(urls, get_table))
View(df)
clean_df <- function(df) {
clean <- function(col) {
col <- gsub("$", "", col, fixed = TRUE)
col <- gsub("%", "", col, fixed = TRUE)
col <- gsub(",", "", col, fixed = TRUE)
col <- gsub("^", "", col, fixed = TRUE)
return(col)
}
df <- clean_df(df)
library(XML)
# Step 1: construct URLs
urls <- paste("http://www.boxofficemojo.com/people/?view=Actor&pagenum=", 1:3, "&sort=person&order=ASC&p=.htm", sep = "")
# Step 2: scrape website
get_table <- function(u) {
table <- readHTMLTable(u)[[3]]
names(table) <- c("Actor", "Total.Gross", "Num.Movies", "Avg.Per.Movie", "No.1 Movie", "Gross.of.No.1.Movie")
df <- as.data.frame(lapply(table[-1, ], as.character), stringsAsFactors=FALSE)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
df <- do.call("rbind", lapply(urls, get_table))
# Step 3: clean dataframe
clean_df <- function(df) {
clean <- function(col) {
col <- gsub("$", "", col, fixed = TRUE)
col <- gsub("%", "", col, fixed = TRUE)
col <- gsub(",", "", col, fixed = TRUE)
col <- gsub("^", "", col, fixed = TRUE)
return(col)
}
df <- clean_df(df)
clean_df <- function(df) {
clean <- function(col) {
col <- gsub("$", "", col, fixed = TRUE)
col <- gsub("%", "", col, fixed = TRUE)
col <- gsub(",", "", col, fixed = TRUE)
col <- gsub("^", "", col, fixed = TRUE)
return(col)
}
}
df <- clean_df(df)
library(XML)
# Step 1: construct URLs
urls <- paste("http://www.boxofficemojo.com/people/?view=Actor&pagenum=", 1:3, "&sort=person&order=ASC&p=.htm", sep = "")
# Step 2: scrape website
get_table <- function(u) {
table <- readHTMLTable(u)[[3]]
names(table) <- c("Actor", "Total.Gross", "Num.Movies", "Avg.Per.Movie", "No.1 Movie", "Gross.of.No.1.Movie")
df <- as.data.frame(lapply(table[-1, ], as.character), stringsAsFactors=FALSE)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
df <- do.call("rbind", lapply(urls, get_table))
# Step 3: clean dataframe
clean_df <- function(df) {
clean <- function(col) {
col <- gsub("$", "", col, fixed = TRUE)
col <- gsub("%", "", col, fixed = TRUE)
col <- gsub(",", "", col, fixed = TRUE)
col <- gsub("^", "", col, fixed = TRUE)
return(col)
}
df <- sapply(df, clean)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
df <- clean_df(df)
View(df)
View(df)
str(df)
View(df)
View(df)
# Step 4: set column types
s <- c(2:4, 5)
df[, s] <- sapply(df[, s], as.numeric)
View(df)
library(XML)
# Step 1: construct URLs
urls <- paste("http://www.boxofficemojo.com/people/?view=Actor&pagenum=", 1:3, "&sort=person&order=ASC&p=.htm", sep = "")
# Step 2: scrape website
get_table <- function(u) {
table <- readHTMLTable(u)[[3]]
names(table) <- c("Actor", "Total.Gross", "Num.Movies", "Avg.Per.Movie", "No.1 Movie", "Gross.of.No.1.Movie")
df <- as.data.frame(lapply(table[-1, ], as.character), stringsAsFactors=FALSE)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
df <- do.call("rbind", lapply(urls, get_table))
# Step 3: clean dataframe
clean_df <- function(df) {
clean <- function(col) {
col <- gsub("$", "", col, fixed = TRUE)
col <- gsub("%", "", col, fixed = TRUE)
col <- gsub(",", "", col, fixed = TRUE)
col <- gsub("^", "", col, fixed = TRUE)
return(col)
}
df <- sapply(df, clean)
df <- as.data.frame(df, stringsAsFactors=FALSE)
return(df)
}
df <- clean_df(df)
# Step 4: set column types
s <- c(2:4, 6)
df[, s] <- sapply(df[, s], as.numeric)
View(df)
str(df)
View(df)
View(df)
Actors
View(df)
(22-19)/19
log(10)
#################################################
#Replicating the old model and slides in the deck
library(ggplot2) #to create gorgeous graphics
library(caret) #Used for Machine Learning training and validating
setwd("/mnt/apic/BI Team/HQ Release Regression 2016/2. Data/2. Clean Data")
df <- read.csv("regressionraw_2016_03_w_HV v2.csv")
#Regression Slide with confidence intervals
lm.original <- lm(log(WW210) ~ WW.Box + Box...Days.to.HQ + A + Animation + Adventure + Comedy + Drama + Romantic.Comedy + Horror.Thriller + PG.13 + R + Has.CAM., data = df)
summary(lm.original)
confint(lm.original, level = .80)
url <- "http://amshq.org/School-Resources/Find-a-School"
library(XML)
table <-readHTMLTable(url)
url <- "http://www.montessori-namta.org/School-Directory"
table <-readHTMLTable(url)
url <- "http://www.montessoricensus.org/school-maps/public/CA"
table <-readHTMLTable(url)
table[1]
str(table)
url <- "http://www.montessoricensus.org/schools/blue-oak-charter-montessori"
table <-readHTMLTable(url)
setwd("~/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts")
setwd("~/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015")
library(tm)
#Directory with TV Scripts
setwd("~/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015")
files <- list.files(pattern = "pdf$")
Rpdf <- readPDF(control = list(text = "-layout"))
scripts <- Corpus(URISource(files), readerControl = list(reader = Rpdf))
?vsource
??vsource
scripts <- Corpus(DirSource(files), readerControl = list(reader = Rpdf))
getwd()
path <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
Rpdf <- readPDF(control = list(text = "-layout"))
scripts <- Corpus(DirSource(path), readerControl = list(reader = Rpdf))
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
#Data were collected from a number of sites including:
#http://thescriptlab.com/screenwriting-101/screenplay/download-scripts#
#http://www.dailyscript.com/movie.html
library(tm)
#set options
options(stringsAsFactors = FALSE)
#Directory with TV Scripts
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
myfiles
setwd("~/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64")
getwd()
#Data were collected from a number of sites including:
#http://thescriptlab.com/screenwriting-101/screenplay/download-scripts#
#http://www.dailyscript.com/movie.html
library(tm)
#set options
options(stringsAsFactors = FALSE)
#Directory with TV Scripts
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe', paste0('"', i, '"')), wait = FALSE) )
#Data were collected from a number of sites including:
#http://thescriptlab.com/screenwriting-101/screenplay/download-scripts#
#http://www.dailyscript.com/movie.html
library(tm)
#set options
options(stringsAsFactors = FALSE)
#Directory with TV Scripts
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe"', paste0('"', i, '"')), wait = FALSE) )
#The readPDF function has a control argument which we use to pass options to our PDF extraction engine. This has to be in the form of a list, so we wrap our options in the list function.
Rpdf <- readPDF(control = list(text = "-layout"))
scripts <- Corpus(DirSource(path), readerControl = list(reader = Rpdf))
dest
list.files()
#Data were collected from a number of sites including:
#http://thescriptlab.com/screenwriting-101/screenplay/download-scripts#
#http://www.dailyscript.com/movie.html
library(tm)
#set options
options(stringsAsFactors = FALSE)
#Directory with TV Scripts
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe"', paste0('"', i, '"')), wait = FALSE) )
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe"', paste0('"', i, '"')), wait = FALSE) )
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe"', paste0('"', i, '"')), wait = FALSE) )
getwd()
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
myfiles
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe"', paste0('"', i, '"')), wait = FALSE) )
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe"',
paste0('"', i, '"')), wait = FALSE) )
#Data were collected from a number of sites including:
#http://thescriptlab.com/screenwriting-101/screenplay/download-scripts#
#http://www.dailyscript.com/movie.html
library(tm)
# folder with 1000s of PDFs
dest <- "/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/5. 2015"
# make a vector of PDF file names
myfiles <- list.files(path = dest, pattern = "pdf",  full.names = TRUE)
# convert each PDF file that is named in the vector into a text file
# text file is created in the same directory as the PDFs
# note that my pdftotext.exe is in a different location to yours
lapply(myfiles, function(i) system(paste('"/Users/jjespinoza/Documents/HollywoodModels/0. Data/1. Raw Data /0. TV Scripts - 2011-2015/xpdfbin-mac-3.04/bin64/pdftotext.exe"', paste0('"', i, '"')), wait = FALSE) )
